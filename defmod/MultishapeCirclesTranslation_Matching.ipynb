{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import defmod as dm\n",
    "import multimodule_usefulfunctions as mm \n",
    "import hamiltonian_multishape as ham\n",
    "import kernels as ker\n",
    "import model_MultiShapeCirclesTranslation as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define reference and template shape\n",
    "r = [3,2]\n",
    "origin1 = [[-3,0], [6,6]]\n",
    "origin2 = [[0,3], [6,4]]\n",
    "nb_points = [10,7]\n",
    "\n",
    "source = mm.multipleCircles(origin1, r ,nb_points)\n",
    "target = mm.multipleCircles(origin2, r ,nb_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Deformation Modules\n",
    "dim = 2\n",
    "nb_shapes = 2\n",
    "\n",
    "# Module 1: Translation of first circle\n",
    "sigma1 = 10\n",
    "trans1 = dm.deformationmodules.Translations(dim, 1, sigma1)\n",
    "\n",
    "# Module 2: Translation of second circle\n",
    "sigma2 = 10\n",
    "trans2 = dm.deformationmodules.Translations(dim,1, sigma2)\n",
    "\n",
    "# Module 3: Background Module\n",
    "sigma3 = 1.5\n",
    "nb_pts = nb_points[0] + nb_points[1]\n",
    "background = dm.deformationmodules.Translations(dim, nb_pts, sigma3)\n",
    "\n",
    "\n",
    "module_list = [trans1, trans2, background]\n",
    "dim_controls = dim*(1+1+nb_pts)\n",
    "gd_list = [source[0], source[1], torch.cat([source[0], source[1]],0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = [*target, torch.cat([target[0], target[1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_list = [sigma1, sigma2, sigma3]\n",
    "z = [mm.computeCenter(source[0]), mm.computeCenter(source[1])]\n",
    "\n",
    "#initialize gd and momentum\n",
    "mom_tmp0 = np.zeros([nb_points[0], dim])\n",
    "mom_tmp1 = np.zeros([nb_points[1], dim])\n",
    "gd0_list = [source[0], source[1], torch.cat([source[0], source[1]],0)]\n",
    "mom0_list = [torch.tensor(mom_tmp0.copy(), requires_grad=True, dtype=torch.float32), torch.tensor(mom_tmp1.copy(),requires_grad=True, dtype=torch.float32), torch.tensor(np.zeros(gd_list[2].shape),requires_grad=True, dtype=torch.float32)]\n",
    "\n",
    "# Constraints (identity)\n",
    "Constr1 = torch.cat([torch.eye(nb_points[0]), torch.zeros([nb_points[0], nb_points[1]]), -torch.eye(nb_points[0]), torch.zeros([nb_points[0], nb_points[1]])], 1)\n",
    "Constr2 = torch.cat([torch.zeros([nb_points[1], nb_points[0]]), torch.eye(nb_points[1]), torch.zeros([nb_points[1], nb_points[0]]), -torch.eye(nb_points[1]),], 1)\n",
    "Constr = [Constr1, Constr2]\n",
    "\n",
    "# reduced Hamiltonian \n",
    "dim_control = [[1,2], [1,2], [nb_pts,2]]\n",
    "H = ham.Hamiltonian_Multishape(module_list, dim_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: tensor(0., grad_fn=<AddBackward0>)\n",
      "attach: tensor(33.1301, grad_fn=<AddBackward0>)\n",
      "gamma: 0.01\n",
      "total: tensor(33.1301, grad_fn=<AddBackward0>)\n",
      "cost: tensor(0., grad_fn=<AddBackward0>)\n",
      "attach: tensor(33.1301, grad_fn=<AddBackward0>)\n",
      "gamma: 0.01\n",
      "total: tensor(33.1301, grad_fn=<AddBackward0>)\n",
      "cost: tensor(0., grad_fn=<AddBackward0>)\n",
      "attach: tensor(33.1301, grad_fn=<AddBackward0>)\n",
      "gamma: 0.01\n",
      "total: tensor(33.1301, grad_fn=<AddBackward0>)\n",
      " iter : 0  ,total energy: 33.1301155090332\n",
      "cost: tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "attach: tensor(33.3014, grad_fn=<AddBackward0>)\n",
      "gamma: 0.01\n",
      "total: tensor(33.3014, grad_fn=<AddBackward0>)\n",
      "tensor(1, dtype=torch.uint8) tensor(0, dtype=torch.uint8) tensor(0, dtype=torch.uint8)\n",
      "tensor(0, dtype=torch.uint8)\n",
      "False\n",
      "convergence True\n",
      "cost: tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "attach: tensor(33.3014, grad_fn=<AddBackward0>)\n",
      "gamma: 0.01\n",
      "total: tensor(33.3014, grad_fn=<AddBackward0>)\n",
      " iter : 1  ,total energy: 33.30139923095703\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "reg_param = 10**-2 # regularisation parameter\n",
    "\n",
    "gd0_tensor = torch.cat([gd0_list[0], gd0_list[1], gd0_list[2]],0)\n",
    "mom0_tensor = torch.cat([mom0_list[0], mom0_list[1], mom0_list[2]],0)\n",
    "    \n",
    "EnergyFunctional = model.EnergyFunctional(module_list, H, Constr, target_list, sigma_list, dim, reg_param)\n",
    "gradE = torch.autograd.grad(EnergyFunctional.energy_tensor(gd0_tensor, mom0_tensor), mom0_tensor)\n",
    "    \n",
    "# do registration\n",
    "X = [gd0_tensor, mom0_tensor]\n",
    "X = model.gradientdescent(EnergyFunctional.energy_tensor, EnergyFunctional.gradE, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(63.1251, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom = EnergyFunctional.tensor2list(X[1])\n",
    "reg_param*EnergyFunctional.cost(gd0_list, mom)+ EnergyFunctional.attach(gd0_list, mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if autograd is correct\n",
    "\n",
    "#torch.autograd.gradcheck(EnergyFunctional.energy_tensor, (gd0_tensor, mom0_tensor), eps=1e-2, atol=1e-2, raise_exception=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2869, -0.6388]]),\n",
       " tensor([[-0.5057, -0.2373]]),\n",
       " tensor([[-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.2622, -0.5838],\n",
       "         [-0.4859, -0.2280],\n",
       "         [-0.4859, -0.2280],\n",
       "         [-0.4859, -0.2280],\n",
       "         [-0.4859, -0.2280],\n",
       "         [-0.4859, -0.2280],\n",
       "         [-0.4859, -0.2280],\n",
       "         [-0.4859, -0.2280]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if gradient wrt controls is zero\n",
    "mom = [torch.randn(mom0_list[0].shape, requires_grad=True), torch.randn(mom0_list[1].shape,requires_grad=True), torch.randn(mom0_list[2].shape,requires_grad=True)]\n",
    "gd, _, control = EnergyFunctional.shoot(gd0_list, mom)\n",
    "i = 0\n",
    "z_list = [mm.computeCenter(gd[i][0]), mm.computeCenter(gd[i][1]), gd[i][2]]\n",
    "torch.autograd.grad(EnergyFunctional.cost(z_list, control[i]), control[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n",
      "tensor(2.4707, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)],\n",
       " [tensor([[-0.2869, -0.6388]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.5057, -0.2373]], grad_fn=<MmBackward>),\n",
       "  tensor([[-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.1818, -0.4048],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469],\n",
       "          [-0.3129, -0.1469]], grad_fn=<AddBackward0>)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(control)):\n",
    "    z_list = [mm.computeCenter(gd[i][0]), mm.computeCenter(gd[i][1]), gd[i][2]]\n",
    "    print(EnergyFunctional.cost(z_list, control[i]))\n",
    "control\n",
    "# the control is constant over time, does that make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
